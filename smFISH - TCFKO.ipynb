{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditiondct(conditionlist=[],startstop=[[]]):\n",
    "    cd={}\n",
    "    for i in range(len(conditionlist)):\n",
    "        llist=[]\n",
    "        for j in range(startstop[i][0],startstop[i][1]+1):\n",
    "            llist.append(\"L\"+str(j))\n",
    "        cd[conditionlist[i]]=llist\n",
    "    return cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "genelist=['Dapi','Glul','Cps1','Gls2']#order of channels\n",
    "path=r\"your/destination/path\"\n",
    "imagepath=r\"your/image/path\"\n",
    "conditiondict=conditiondct([\"CON\",\"L-KO\"],[[17,21],[27,31]])#[\"CON\",\"L-KO\"],[[firstmouse1,finalmouse1],[firstmouse2,finalmouse2]]\n",
    "channeldict={\"C1\":genelist[0],\"C2\":genelist[1],\"C3\":genelist[2],\"C4\":genelist[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93dd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####    LOAD LIBRARIES/PACKAGES    ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import bigfish.detection as detection\n",
    "import bigfish.stack as stack\n",
    "import bigfish.plot as plot\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from skimage.draw import polygon_perimeter, polygon\n",
    "from skimage import io\n",
    "from skimage.io import imread, imsave\n",
    "from scipy import ndimage\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import shutil\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "####    PREPROCESS    ####\n",
    "ncpath=os.path.join(path+\"Negative Controls/\")\n",
    "try:\n",
    "    os.mkdir(ncpath)\n",
    "except:\n",
    "    pass\n",
    "for i in os.listdir(imagepath):\n",
    "    if i.endswith(\".tif\"):\n",
    "        dire=os.path.join(path,i.rsplit('.',1)[0])\n",
    "        try:\n",
    "            os.mkdir(dire)\n",
    "        except:\n",
    "            pass\n",
    "if genelist[0]!='Dapi':\n",
    "    for i,j in enumerate(genelist):\n",
    "        if j == 'Dapi':\n",
    "            dapiindex=i\n",
    "            for k in os.listdir(imagepath):\n",
    "                l=list(k)\n",
    "                if l[1]==str(1):\n",
    "                    l[1]=str(5)\n",
    "                    os.rename(imagepath+k,imagepath+\"\".join(list(l)))\n",
    "            for k in os.listdir(imagepath):\n",
    "                l=list(k)\n",
    "                if l[1]==str(i+1):\n",
    "                    l[1]=str(1)\n",
    "                    os.rename(imagepath+k,imagepath+\"\".join(list(l)))\n",
    "            for k in os.listdir(imagepath):\n",
    "                l=list(k)\n",
    "                if l[1]==str(5):\n",
    "                    l[1]=str(i+1)\n",
    "                    os.rename(imagepath+k,imagepath+\"\".join(list(l)))\n",
    "    genelist.append(genelist[0])\n",
    "    genelist[0]=genelist[dapiindex]\n",
    "    genelist[dapiindex]=genelist[4]\n",
    "    genelist=genelist[0:4]\n",
    "    print(\"Updated Genelist: \"+str(genelist))\n",
    "try:\n",
    "    os.mkdir(os.path.join(path,\"\",\"Thresholding\"))\n",
    "except:\n",
    "    pass\n",
    "for i in genelist:\n",
    "    if i!='Dapi':\n",
    "        i=os.path.join(path,'Thresholding',i)\n",
    "        try:\n",
    "            os.mkdir(i)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63cb1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####    CELLPROFILER    ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "####    MOVE NEGATIVE CONTROLS    ####\n",
    "for i in os.listdir(path):\n",
    "    if i.endswith(\")\"):\n",
    "        shutil.move(os.path.join(path,i), os.path.join(ncpath,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "####    THRESHOLDING FUNCTIONS    ####\n",
    "def run_thresholding(img, voxel_size=(3,3), spot_radius=(5,5)):#from patrick\n",
    "    spots,thresh= detection.detect_spots(\n",
    "                    images = img,\n",
    "                    voxel_size=voxel_size,\n",
    "                    return_threshold=True,\n",
    "                    spot_radius=spot_radius)\n",
    "    \n",
    "    spots_post_decomposition, _, _ = detection.decompose_dense(\n",
    "                    image=img,\n",
    "                    spots=spots,\n",
    "                    voxel_size=voxel_size,\n",
    "                    spot_radius=spot_radius,\n",
    "                    alpha=0.5,#mess with this for intensity stuff - higher = less\n",
    "                    beta=1,\n",
    "                    gamma=5)\n",
    "    spots_post_clustering, clusters = detection.detect_clusters(\n",
    "                    spots=spots_post_decomposition,\n",
    "                    voxel_size=voxel_size,\n",
    "                    radius=350,\n",
    "                    nb_min_spots=4)\n",
    "    return spots_post_clustering, thresh\n",
    "def check_thresholding(img, threshold, voxel_size=(103,103), spot_radius=(150,150)):#from patrick\n",
    "    spots= detection.detect_spots(\n",
    "                    images = img,\n",
    "                    threshold = threshold,\n",
    "                    voxel_size=voxel_size,\n",
    "                    spot_radius=spot_radius)\n",
    "    \n",
    "    spots_post_decomposition, _, _ = detection.decompose_dense(\n",
    "                    image=img,\n",
    "                    spots=spots,\n",
    "                    voxel_size=voxel_size,\n",
    "                    spot_radius=spot_radius,\n",
    "                    alpha=0.5,#mess with this for intensity stuff - higher = less\n",
    "                    beta=1,\n",
    "                    gamma=5)\n",
    "    spots_post_clustering, clusters = detection.detect_clusters(\n",
    "                    spots=spots_post_decomposition,\n",
    "                    voxel_size=voxel_size,\n",
    "                    radius=350,\n",
    "                    nb_min_spots=4)\n",
    "    \n",
    "    return spots_post_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66308538",
   "metadata": {},
   "outputs": [],
   "source": [
    "####    RUN THRESHOLDING    ####\n",
    "for i in os.listdir(ncpath):\n",
    "    if re.search(\"^L[0-9]\",i):\n",
    "        c2 = stack.read_image(ncpath+i + '/C2.tiff')\n",
    "        c3 = stack.read_image(ncpath+i + '/C3.tiff')\n",
    "        c4 = stack.read_image(ncpath+i + '/C4.tiff')\n",
    "        c2_spots,c2_thresh=run_thresholding(c2)\n",
    "        c3_spots,c3_thresh=run_thresholding(c3)\n",
    "        c4_spots,c4_thresh=run_thresholding(c4)\n",
    "        print(i.split(\"_\")[-1]+\"  C2: \"+str(c2_thresh)+\"   C3: \"+str(c3_thresh)+\"   C4: \"+str(c4_thresh))\n",
    "#         plot.plot_detection(c2, spots=c2_spots[:, :2], shape = 'circle',\n",
    "#                             radius=3, color='red', linewidth=1, fill=False, contrast=False,\n",
    "#                             title=genelist[1]+ \": \"+str(c2_thresh), ext='png', show=False,\n",
    "#                             path_output=os.path.join(path,\"Thresholding\",genelist[1], (i + '_spot_detection')));\n",
    "\n",
    "#         plot.plot_detection(c3, spots=c3_spots[:, :2], shape = 'circle',\n",
    "#                             radius=3, color='red', linewidth=1, fill=False, contrast=False,\n",
    "#                             title=genelist[2]+ \": \"+str(c3_thresh), ext='png', show=False,\n",
    "#                             path_output=os.path.join(path,\"Thresholding\", genelist[2], (i+ '_spot_detection')));\n",
    "\n",
    "#         plot.plot_detection(c4, spots=c4_spots[:, :2], shape = 'circle',\n",
    "#                             radius=3, color='red', linewidth=1, fill=False, contrast=False,\n",
    "#                             title=genelist[3]+ \": \"+str(c4_thresh), ext='png', show=False,\n",
    "#                             path_output=os.path.join(path ,\"Thresholding\", genelist[3],(i + '_spot_detection')));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e778c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshlist=[0,40,70,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914110d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####    CHECK THRESHOLDING    ####\n",
    "print(genelist)\n",
    "for i in os.listdir(ncpath):\n",
    "    if re.search(\"^L[0-9]\",i):\n",
    "        c2 = stack.read_image(ncpath+i + '/C2.tiff')\n",
    "        c3 = stack.read_image(ncpath+i + '/C3.tiff')\n",
    "        c4 = stack.read_image(ncpath+i + '/C4.tiff')\n",
    "        c2_spots=check_thresholding(c2,threshlist[1])\n",
    "        c3_spots=check_thresholding(c3,threshlist[2])\n",
    "        c4_spots=check_thresholding(c4,threshlist[3])\n",
    "        #print(i.split(\"_\")[-1]+\"  C2: \"+str(len(c2_spots))+\"   C3: \"+str(len(c3_spots))+\"   C4: \"+str(len(c4_spots)))\n",
    "        print(i)\n",
    "        plot.plot_detection(c2, spots=c2_spots[:, :2], shape = 'circle',\n",
    "                    radius=3, color='red', linewidth=1, fill=False, contrast=False,\n",
    "                    title=genelist[1]+ \": \"+str(threshlist[1]), ext='png', show=True,\n",
    "                    path_output=os.path.join(path,\"Thresholding\",genelist[1],(i + '_spot_detection')));\n",
    "\n",
    "        plot.plot_detection(c3, spots=c3_spots[:, :2], shape = 'circle',\n",
    "                    radius=3, color='red', linewidth=1, fill=False, contrast=False,\n",
    "                    title=genelist[2]+ \": \"+str(threshlist[2]), ext='png', show=True,\n",
    "                    path_output=os.path.join(path,\"Thresholding\", genelist[2],(i+ '_spot_detection')));\n",
    "\n",
    "        plot.plot_detection(c4, spots=c4_spots[:, :2], shape = 'circle',\n",
    "                    radius=3, color='red', linewidth=1, fill=False, contrast=False,\n",
    "                    title=genelist[3]+ \": \"+str(threshlist[3]), ext='png', show=True,\n",
    "                    path_output=os.path.join(path ,\"Thresholding\", genelist[3],(i + '_spot_detection')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorbar(mappable):\n",
    "    \"\"\"\n",
    "    Function to place colorbars next to images and guarantee that they have the\n",
    "    same size.\n",
    "    From: https://joseph-long.com/writing/colorbars/\n",
    "    More info: https://matplotlib.org/mpl_toolkits/axes_grid/users/overview.html#colorbar-whose-height-or-width-in-sync-with-the-master-axes\n",
    "    \"\"\"\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    return fig.colorbar(mappable, cax=cax)\n",
    "\n",
    "def log_message(msg, callback_fun=None):\n",
    "    \"\"\" Display log, either terminal or any callback accepting a string as input.\n",
    "    Parameters\n",
    "    ----------\n",
    "    msg : [string]\n",
    "        [description]\n",
    "    callback_fun : [type], optional\n",
    "        [description], by default None\n",
    "    \"\"\"\n",
    "    if callback_fun:\n",
    "        callback_fun(msg)\n",
    "    else:\n",
    "        print(msg)\n",
    "\n",
    "# Function to create filled masks\n",
    "def make_mask(roi_pos,img_size):\n",
    "    rr, cc = polygon(roi_pos[:, 0], roi_pos[:, 1])\n",
    "    # Make sure it's not outside\n",
    "    rr[rr < 0] = 0\n",
    "    rr[rr > img_size[0] - 1] = img_size[0] - 1\n",
    "    cc[cc < 0] = 0\n",
    "    cc[cc > img_size[1] - 1] = img_size[1] - 1\n",
    "    # Generate mask\n",
    "    mask = np.zeros(img_size, dtype=np.uint8)\n",
    "    mask[rr, cc] = 1\n",
    "    return mask\n",
    "\n",
    "def read_annotation(annotation_file):\n",
    "    # Load annotation from json file: Note that the coordinates in the annotations\n",
    "    # are stored as (X,Y), further  Y has to be flipped\n",
    "    if not os.path.isfile(annotation_file):\n",
    "        raise FileNotFoundError(f\"No annotation file found : {annotation_file}\")\n",
    "    with open(annotation_file, encoding='utf-8-sig') as fh:\n",
    "        data_json = json.load(fh)\n",
    "    # Read image size from annotations\n",
    "    if 'bbox' in data_json:\n",
    "        img_size = (int(data_json['bbox'][2]-data_json['bbox'][0]+1),\n",
    "                           int(data_json['bbox'][3]-data_json['bbox'][1]+1))\n",
    "        img_size = (img_size[1],img_size[0])\n",
    "    return data_json, img_size\n",
    "  \n",
    "\n",
    "\n",
    "def run_detection(img, threshold, voxel_size=(103,103), spot_radius=(150,150)):\n",
    "    spots= detection.detect_spots(\n",
    "                    images = img,\n",
    "                    threshold = threshold,\n",
    "                    voxel_size=voxel_size,\n",
    "                    spot_radius=spot_radius)\n",
    "    \n",
    "    spots_post_decomposition, _, _ = detection.decompose_dense(\n",
    "                    image=img,\n",
    "                    spots=spots,\n",
    "                    voxel_size=voxel_size,\n",
    "                    spot_radius=spot_radius,\n",
    "                    alpha=0.5,\n",
    "                    beta=1,\n",
    "                    gamma=5)\n",
    "    return spots_post_decomposition\n",
    "\n",
    "def makejson(folder):\n",
    "    cv=np.load(folder+\"/CV.npy\")\n",
    "    pl=np.load(folder+\"/PL.npy\")\n",
    "    cvl=[]\n",
    "    pll=[]\n",
    "    for i in range(len(np.where(cv==1)[1])):\n",
    "        cvl.append([int(np.where(cv==1)[1][i]),cv.shape[0]-int(np.where(cv==1)[0][i])])\n",
    "    for i in range(len(np.where(pl==1)[1])):\n",
    "        pll.append([int(np.where(pl==1)[1][i]),pl.shape[0]-int(np.where(pl==1)[0][i])])\n",
    "    \n",
    "    annotations={\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"geometry\":{\"type\":\"polygon\",\"coordinates\":[cvl]},\"properties\":{\"label\":\"CV\"}},{\"type\":\"Feature\",\"geometry\":{\"type\":\"polygon\",\"coordinates\":[pll]},\"properties\":{\"label\":\"PL\"}}],\"bbox\":[0,0,len(cv[0]),len(cv[:,0])]}\n",
    "    file1=open(folder+\"/annotation.json\",\"wt\")\n",
    "    file1.write(json.dumps(annotations))\n",
    "    file1.close()\n",
    "    \n",
    "def read_FQ_matlab(file_open):\n",
    "  path=file_open.rsplit(\"\\\\\",1)[0]\n",
    "  file=file_open.split('\\\\')[-1]\n",
    "  gene=genelist[int(file.split('-')[0][1])-1]\n",
    "  img = stack.read_image(file_open)\n",
    "  threshold=threshlist[int(file.split('-')[0][1])-1]\n",
    "  spots=run_detection(img,threshold)\n",
    "  dapi= path+\"/C\"+str(genelist.index('Dapi'))\n",
    "  fq_dict={'gene':gene,'spots':spots,\"img\":img,\"file_names\":{\"smFISH\":file_open,\"Dapi\":dapi}}\n",
    "  return fq_dict\n",
    "\n",
    "def get_rna(fq_dict):\n",
    "  return fq_dict['spots']\n",
    "\n",
    "def folder_scan_process(folder_root,log_msg_callback = None,log_prog_callback=None):\n",
    "    ''' Scan folders an process when C1 file is present'''\n",
    "    region_labels   = ('CV','PL')\n",
    "    # Recursive search of specified directory\n",
    "    folders_proc = []\n",
    "    for root, dirnames, filenames in os.walk(folder_root):\n",
    "        for filename in filenames:\n",
    "            if filename.startswith(\"C1\"):\n",
    "                folders_proc.append(root)\n",
    "    for folder_process in folders_proc:\n",
    "        log_message(f'\\n\\n Processing folder: {folder_process}',callback_fun=log_msg_callback)\n",
    "        process_folder(folder_process,region_labels,log_msg_callback=log_msg_callback,log_prog_callback=log_prog_callback)\n",
    "def process_folder(folder_process,region_labels,log_msg_callback = None,log_prog_callback=None):\n",
    "    '''\n",
    "    Process folder containing FQ analysis results and an ImJoy annotation.\n",
    "    '''\n",
    "    if 'annotation.json'not in os.listdir(folder_process):\n",
    "        makejson(folder_process)\n",
    "    # Open annotations and create masks\n",
    "    annotation_file = os.path.join(folder_process,\"annotation.json\")\n",
    "    data_json, img_size =read_annotation(annotation_file)\n",
    "\n",
    "    # Note that coordinates are exchanged and y flipped\n",
    "    for feat_idx, feat in enumerate(data_json['features']):\n",
    "        label = feat['properties']['label']\n",
    "\n",
    "        if label == region_labels[0]:\n",
    "            log_message(f'Annotation for first region ({region_labels[0]}) found',callback_fun=log_msg_callback)\n",
    "            cv_pos = np.squeeze(np.asarray(feat['geometry']['coordinates']))\n",
    "            cv_pos[:,[0, 1]] = cv_pos[:,[1, 0]]\n",
    "            cv_pos[:,0] = -1*cv_pos[:,0]+img_size[0]\n",
    "            reg1_mask = make_mask(cv_pos,img_size)\n",
    "\n",
    "        elif label == region_labels[1]:\n",
    "            log_message(f'Annotation for second region ({region_labels[1]}) found',callback_fun=log_msg_callback)\n",
    "            pl_pos = np.squeeze(np.asarray(feat['geometry']['coordinates']))\n",
    "            pl_pos[:,[0, 1]] = pl_pos[:,[1, 0]]\n",
    "            pl_pos[:,0] = -1*pl_pos[:,0]+img_size[0]\n",
    "            reg2_mask = make_mask(pl_pos,img_size)\n",
    "\n",
    "    ### Make masks and measure distance of P.L. to C.V.\n",
    "\n",
    "    # Assemble distance map: outside positive, inside negative\n",
    "    reg1_mask_distTrans_inside = ndimage.distance_transform_edt(reg1_mask)\n",
    "    reg1_mask_distTrans_outside = ndimage.distance_transform_edt(~reg1_mask.astype(bool))\n",
    "\n",
    "    reg1_mask_distTrans = np.copy(reg1_mask_distTrans_outside)\n",
    "    reg1_mask_distTrans[reg1_mask_distTrans_inside>0] = -reg1_mask_distTrans_inside[reg1_mask_distTrans_inside>0]\n",
    "    \n",
    "    ### Test\n",
    "    reg2_mask_distTrans_inside = ndimage.distance_transform_edt(reg2_mask)\n",
    "    reg2_mask_distTrans_outside = ndimage.distance_transform_edt(~reg2_mask.astype(bool))\n",
    "\n",
    "    reg2_mask_distTrans = np.copy(reg2_mask_distTrans_outside)\n",
    "    reg2_mask_distTrans[reg2_mask_distTrans_inside>0] = -reg2_mask_distTrans_inside[reg2_mask_distTrans_inside>0]\n",
    "\n",
    "    # Center of mass of region 2 (portal lobe)\n",
    "    reg2_com      = np.asarray(ndimage.measurements.center_of_mass(reg2_mask.astype(bool))).astype('int')\n",
    "    reg2_mask_dist= ndimage.distance_transform_edt(reg2_mask)\n",
    "    reg2_dist = reg2_mask_dist[reg2_com[0],reg2_com[1]]\n",
    "    reg2_distReg1 = reg1_mask_distTrans[reg2_com[0],reg2_com[1]]-reg2_dist\n",
    "\n",
    "    \n",
    "    # Loop over all FQ result files\n",
    "    for file in os.listdir(folder_process):\n",
    "        if '.tif' in file:\n",
    "\n",
    "            file_open = os.path.join(folder_process,file)\n",
    "\n",
    "            # Get information (path, file name) to save results\n",
    "            drive, path_and_file = os.path.splitdrive(file_open)\n",
    "            path, file = os.path.split(path_and_file)\n",
    "            file_base, ext = os.path.splitext(file)\n",
    "\n",
    "            path_save = os.path.join(drive,path, 'analysis__exprGradient')\n",
    "            if not os.path.isdir(path_save):\n",
    "                os.makedirs(path_save)\n",
    "\n",
    "            fq_dict = read_FQ_matlab(file_open)\n",
    "            spots_all = get_rna(fq_dict)\n",
    "            spots_pos = spots_all[:,[0, 1]].astype('int')\n",
    "\n",
    "            # Open FISH image\n",
    "            file_FISH_img = os.path.join(folder_process,fq_dict['file_names']['smFISH'])\n",
    "            img_FISH  = imread(file_FISH_img)\n",
    "\n",
    "            ### Distance measurements\n",
    "            reg1_mask_distTrans_norm = np.divide(reg1_mask_distTrans,reg1_mask_distTrans+reg2_mask_distTrans)\n",
    "\n",
    "            # Distance of all RNAs to region 1, RNAs inside the region have negative values\n",
    "            RNAdist_norm = reg1_mask_distTrans_norm[spots_pos[:,0],spots_pos[:,1]]\n",
    "\n",
    "            # Bins for histogram\n",
    "            RNAdist_norm_max = np.amax(RNAdist_norm)\n",
    "            RNAdist_norm_min = np.amin(RNAdist_norm)\n",
    "            bins=np.arange(np.around(RNAdist_norm_min,1)-0.1,RNAdist_norm_max+0.1,0.1)\n",
    "\n",
    "\n",
    "            width = 0.8 * (bins[1] - bins[0])\n",
    "            center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "            # Histogram of RNA distances\n",
    "            count_RNA, bins = np.histogram(RNAdist_norm, bins=bins,density=False)\n",
    "\n",
    "            # Renormalize considering how many pixels are really in the actual image\n",
    "            count_pix = np.diff(list(map(lambda threshold: np.sum(reg1_mask_distTrans_norm <= threshold),bins)))\n",
    "\n",
    "            # Renormalize RNA counts with respect to area\n",
    "            count_RNA_normArea = count_RNA/count_pix\n",
    "\n",
    "            # Summarize all histograms\n",
    "            hist_all = np.stack((center,count_RNA_normArea,count_RNA,count_pix),axis=1)\n",
    "\n",
    "            # Save file with histogram\n",
    "            np.savetxt(os.path.join(path_save, 'hist_expression__' + file_base +  '.txt'), hist_all, fmt='%f \\t %f \\t %f \\t %f',header='Dist_norm [um]\\tCOUNTS_NORM_AREA\\tCOUNTS_RAW\\tPIXEL_COUNTS')\n",
    "\n",
    "            # Plot results and save figure\n",
    "\n",
    "            # PLOT ROI and center of mass\n",
    "            fig1, ax = plt.subplots(3,2,num='dist_enrich')\n",
    "            fig1.set_size_inches((15,12))\n",
    "\n",
    "            # Plot image with region of interest and reference point\n",
    "            img1 = ax[0][0].imshow(img_FISH,cmap=\"hot\")\n",
    "            plt.sca(ax[0][0])   # set current axis\n",
    "            plt.title('Region 1 (green) and 2 (blue)')\n",
    "            ax[0][0].plot(pl_pos[:,1], pl_pos[:,0], '-b',alpha=0.5)\n",
    "            ax[0][0].plot(cv_pos[:,1], cv_pos[:,0], '-g',alpha=0.5)\n",
    "            ax[0][0].get_xaxis().set_visible(False)\n",
    "            ax[0][0].get_yaxis().set_visible(False)\n",
    "            colorbar(img1)\n",
    "\n",
    "            img2 = ax[0][1].imshow(np.digitize(reg1_mask_distTrans_norm,bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]),cmap=\"hot\")\n",
    "            plt.sca(ax[0][1])\n",
    "            plt.title('Detected Spots')\n",
    "            ax[0][1].plot(pl_pos[:,1], pl_pos[:,0], '-b',alpha=0.5)\n",
    "            ax[0][1].plot(cv_pos[:,1], cv_pos[:,0], '-g',alpha=0.5)\n",
    "            ax[0][1].scatter(spots_pos[:,1],spots_pos[:,0],c='cyan',edgecolor='black',marker='.')\n",
    "            ax[0][1].get_xaxis().set_visible(False)\n",
    "            ax[0][1].get_yaxis().set_visible(False)\n",
    "\n",
    "            # Plot distance map and pixel distance histogram\n",
    "            img3 = ax[1][0].imshow(np.digitize(reg1_mask_distTrans_norm,bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]),cmap=\"hot\")\n",
    "            plt.sca(ax[1][0])\n",
    "            plt.title('Renormalized distance from region 1')\n",
    "            ax[1][0].plot(pl_pos[:,1], pl_pos[:,0], '-b')\n",
    "            ax[1][0].plot(cv_pos[:,1], cv_pos[:,0], '-g')\n",
    "            ax[1][0].get_xaxis().set_visible(False)\n",
    "            ax[1][0].get_yaxis().set_visible(False)\n",
    "            colorbar(img3)\n",
    "\n",
    "            plt.sca(ax[1][1])\n",
    "            plt.xlim([0,1])\n",
    "            plt.title('Histogram of all pixel distances')\n",
    "            ax[1][1].bar(center, count_pix, align='center', width=width)\n",
    "            ax[1][1].set_xlabel('Distance [pixel]')\n",
    "            ax[1][1].set_ylabel('# pixel')\n",
    "\n",
    "\n",
    "            # Plot histograms\n",
    "            plt.sca(ax[2][0])\n",
    "            plt.xlim([0,1])\n",
    "            plt.title('Histogram without normalization')\n",
    "            ax[2][0].bar(center, count_RNA, align='center', width=width)\n",
    "            ax[2][0].set_xlabel('Distance [pixel]')\n",
    "            ax[2][0].set_ylabel('# RNAs')\n",
    "\n",
    "            plt.sca(ax[2][1])\n",
    "            plt.xlim([0,1])\n",
    "            plt.title('Histogram: normalized with area')\n",
    "            ax[2][1].bar(center, count_RNA_normArea, align='center', width=width)\n",
    "            ax[2][1].set_xlabel('Normalized distance')\n",
    "            ax[2][1].set_ylabel('Expression level [a.u.]')\n",
    "\n",
    "            fig1.tight_layout(h_pad=0.2)\n",
    "            plt.draw()\n",
    "\n",
    "            plt.savefig(os.path.join(path_save, '_summary_gradient_' + file_base +  '.png'),dpi=200)\n",
    "            plt.close()\n",
    "\n",
    "    log_message(f'Finished processing data!',callback_fun=log_msg_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fb5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####    ANALYSIS    ####\n",
    "folder_scan_process(path,log_msg_callback=None,log_prog_callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4695e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####    COMPILE TXT FILES    ####\n",
    "for r,d,fi in os.walk(path):\n",
    "    for f in fi:\n",
    "        if \".txt\" in f and f.startswith(\"hist\"):\n",
    "            for channel in channeldict:\n",
    "                if channel in f:\n",
    "                    for key in conditiondict:\n",
    "                        if r.rsplit(\"/\",2)[1].split(\"_\")[0] in conditiondict[key]:#C*-key_restofname   .split(\"-\")[1]\n",
    "                                vals=[]\n",
    "                                file1=open(r+\"\\\\\"+f,'r')\n",
    "                                lines=file1.readlines()\n",
    "                                file1.close()\n",
    "                                c=0\n",
    "                                for line in lines:\n",
    "                                    if c!=0:\n",
    "                                        vals.append([line.split(\"\\t\")[0],line.split(\"\\t\")[1],r.rsplit(\"/\",2)[1].split(\"_\")[0]+'-'+r.rsplit(\"/\",2)[1].split(\"\\\\\")[0].split(\"_\")[-1],r.rsplit(\"/\",2)[1].split(\"_\")[0]])\n",
    "                                    c+=1\n",
    "                                file2 = open(path+\"/\"+key+\"_\"+channeldict[channel]+\".txt\",'a')\n",
    "                                file2.write(str(vals))\n",
    "                                file2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe3173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####    GENERATE DATAFRAME    ####\n",
    "j=0\n",
    "for i in os.listdir(path):\n",
    "    if \".txt\" in i:\n",
    "        file=open(path+\"/\"+i,'r')\n",
    "        data=file.read()\n",
    "        file.close()\n",
    "        dl=[i.replace(\"\\'\",\"\").replace('[','').replace(']','').replace('nan','?').split(', ') for i in re.findall(\"\\[(.*?)\\]\", data[1:-1])]\n",
    "        dftmp=pd.DataFrame(dl)\n",
    "        dftmp=dftmp.replace(\" ? \",np.nan)\n",
    "        dftmp=dftmp.replace(\" \",\"\")\n",
    "        dftmp[0]=pd.to_numeric(dftmp[0])\n",
    "        dftmp[1]=pd.to_numeric(dftmp[1])\n",
    "        dftmp=dftmp.loc[(dftmp[0]>0)&(dftmp[0]<1.05)]\n",
    "        dftmp['Gene']=i.split('.')[0].split(\"_\")[-1]\n",
    "        dftmp['Condition']=' '.join(i.split('.')[0].split(\"_\")[0:-1])\n",
    "        if j==0:\n",
    "            df=dftmp\n",
    "        else:\n",
    "            df=pd.concat([df,dftmp], ignore_index=True)\n",
    "        j+=1\n",
    "df=df.rename(columns={0:'X',1:\"Expression Level\",2:\"Image\",3:\"Mouse\"})\n",
    "    \n",
    "dfsum=df.groupby(['Image','Gene'],group_keys=False).apply(np.sum,axis=0)[['Expression Level']].reset_index().rename(columns={'Expression Level':'Sum'})\n",
    "dfn=df.merge(dfsum,on=['Image','Gene'])\n",
    "dfn['Fraction of Lobule']=dfn['Expression Level'].divide(dfn['Sum'])\n",
    "dfn.to_csv(path+\"total_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78551fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####    GENERATE PLOTS    ####\n",
    "def gen_lineplotsmouse(df,gene,yticks):\n",
    "    num_conditions = df['Condition'].nunique()\n",
    "    X0=df.loc[(df['Gene']==gene) & (df['Condition']==df['Condition'].unique()[0])]['X']*10+0.5\n",
    "    X1=df.loc[(df['Gene']==gene) & (df['Condition']==df['Condition'].unique()[1])]['X']*10+0.5\n",
    "    mean0=df.loc[(df['Gene']==gene) & (df['Condition']==df['Condition'].unique()[0])]['Ymean']\n",
    "    mean1=df.loc[(df['Gene']==gene) & (df['Condition']==df['Condition'].unique()[1])]['Ymean']\n",
    "    error0=df.loc[(df['Gene']==gene) & (df['Condition']==df['Condition'].unique()[0])]['Ysem']\n",
    "    error1=df.loc[(df['Gene']==gene) & (df['Condition']==df['Condition'].unique()[1])]['Ysem']\n",
    "    plt.plot(X0,mean0,color=\"#8f0009\")\n",
    "    plt.plot(X1,mean1,color=\"#52D6F4\")\n",
    "    plt.fill_between(X0,mean0-error0,mean0+error0,color=\"#8f0009\",alpha=0.3)\n",
    "    plt.fill_between(X1,mean1-error1,mean1+error1,color=\"#52D6F4\",alpha=0.3)\n",
    "    #plt.title(gene,color='w')\n",
    "    #plt.legend([\"Control\",\"L-KO\"])\n",
    "    plt.yticks(yticks,labels=None)#,color='w')\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xticks(range(1,11),labels=None)#,color='w')\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.tick_params(length=6,width=2)\n",
    "#    plt.axhline(linewidth=5,color='black')\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['bottom'].set_linewidth(2)\n",
    "    plt.gca().spines['left'].set_linewidth(2)\n",
    "    plt.gcf().set_size_inches(3.5,2)\n",
    "    plt.savefig(path+gene+\"_FOL_TCF7L2_notext_2x3.5.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "dfmouse=dfn.groupby(['Condition','Mouse','Gene','X'],group_keys=False)[['Expression Level','Fraction of Lobule']].mean().reset_index()\n",
    "dfmouse=dfmouse.loc[dfmouse.Gene!=\"Dapi\"]\n",
    "dfmouse=dfmouse.rename(columns={\"Fraction of Lobule\":\"Y\"})\n",
    "dfmousemean=dfmouse.groupby(['X','Condition','Gene'],as_index=False).agg({'Y': ['mean','sem']})#.drop(('condition','sem'), axis=1)\n",
    "dfmousemean.columns=dfmousemean.columns.map(''.join)\n",
    "\n",
    "gen_lineplotsmouse(dfmousemean,genelist[1],[0,0.35,0.7])\n",
    "gen_lineplotsmouse(dfmousemean,genelist[2],[0,0.1,0.2])\n",
    "gen_lineplotsmouse(dfmousemean,genelist[3],[0,0.15,0.3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
